<!DOCTYPE html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title> Home </title>
    <link rel="stylesheet" href="styles/home.css">
</head>

<body class="indent">
    <section >
        <h1> The Data Oriented Approach</h1>
        <img src="resources/touch-of-god.jpg" alt="placeholder">
        <p> By Christopher Kollar </p>
    </section>

    <section>
        <div class="blur vbox body-div">
            <h1> Science is a Knowledge Generating System</h1>
            <div class="hbox">
                <div class="item vbox text-wrapper text-wrapper1">
                    <p>
                        There is a shifting trend in scientific research, traditionally driven by conceptual development, it is
                        recently being more influenced by technological development. Technological progress, particularly in the
                        form of machine learning models is opening a new approach to research, the data-driven approach. As the
                        approach to science changes, so does the trust we can place in it changes.
                    </p>
                    <p>
                        Science is an epistemic system, a knowledge generating system. Through the scientific method, it seeks to
                        generate collectively empirically verified knowledge based on a positivistic principal of knowledge: that
                        knowledge is valid only if it can be empirically verified. This is in contrast with the knowledge-generating
                        systems of religion, which tries to generate knowledge of non-physically verifiable phenomena. The trust we
                        place in the knowledge produced by these institutions differ, because their methods of producing knowledge
                        differ.
                    </p>
                </div>
                <div class="item img-wrapper img-wrapper1">
                    <img src="resources/scientific-method.webp" alt="scientific method">
                    <p>
                        https://s-ink.org/the-scientific-method
                    </p>
                </div>
            </div>
            <div class="hbox">
                <div class="item img-wrapper img-wrapper1">
                    <img src="resources/rat.jpeg" alt="placebo rat">
                </div>
                <div class="item vbox text-wrapper text-wrapper1">
                    <p>
                        It has been argued, that the purpose of science is not to generate knowledge, but rather improve society.
                        This is could be described as an instrumentalist approach to science, where the validity of knowledge is
                        less a concern than the utility of knowledge. However, this is not reflected in real scientific practices.
                        In drug research for instance, during randomized control trials a placebo condition is common-practice. We
                        care that the drug works, not just by placebo, but by pharmacological activity. It is demonstrated, that
                        science cannot be explained as having a purely instrumentalist goal of utility, but it has an epistemic
                        goal of actual knowledge as well.
                    </p>
                </div>
            </div>
            <div class="item vbox">
                <p>
                    The epistemic validity, or "truthfulness/certainty" of the knowledge is determined by the set of procedures
                    we have developed around the scientific method. This includes peer review; a collective democratization of
                    knowledge generation. As well as statistical testing; mathematical verification of probability (note: other
                    forms of verification exist). This is built around the theory driven approach to knowledge generation:
                    hypothesis to experiment to observation. New concepts and theories are generated, and increase in likelihood
                    of truth as a body of evidence is gathered.
                    But as a knowledge generating system, if the processes and approaches used to generate the knowledge change,
                    so does the epistemic validity (our trust in knowledge) also change. Additionally, the procedures needed to
                    protect the validity of the knowledge, such as statistical-testing, need to change as well. We will look at
                    these changes in science, and how they effect the validity of the knowledge produced.
                </p>
            </div>
        </div>
    </section>

    <section >
        <h1> Big Tech: Competing Influence in Science </h1>
        <p>
            the field of research is not autonomous, meaning it is subject to external forces and influence. Whether by
            process of lobbying, or conditional funding to pools of funding. There are economic realities science has to
            face, <a href="https://www.deloitte.com/ch/en/Industries/life-sciences-health-care/research/measuring-return-from-pharmaceutical-innovation.html">
            it is very expensive</a>. We see this with the increase in expenditure on R/D from private companies
            <a href="https://www.cbo.gov/publication/57126"> 10x in 2010, from what it was in the 1980s</a>,
            that the market influence can favour certain forms of research over
            others, applied research in particular has more immediate financial benefit for the funding companies
            than fundamental research. These economic realities, and the need for funding creates an external influence
            on research. (Meirmans 2024).
        </p>
        <img src="resources/market-science-field-diagram.png" alt="diagram">
        <p>
            An example of external market influence, acting as a corrupting force can be famously seen in the case of
            Monsanto's Glyphosate herbicide, called RoundUp. Famously, Monsanto hired a panel of independent private
            researchers to publish a ghost written paper on the safety of glyphosate, using the independent researchers
            legitimacy to get published in leading toxicology journals (McHenry 2018). The practice of "ghost writing",
            enabled a privately written paper to gain the scientific legitimacy of the private researchers who would
            sign their name to it. While RoundUp was registered in 1974, it would take until 2015 before the IARC
            Working Group (group that critically reviews papers) to identify glyphosate as a group 2A carcinogenic agent,
            meaning it is possibly carcinogenic to humans (McHenry 2018). Additionally, the Monsanto Panel of private
            researchers would engage with interference of the peer view process, when Charles Healy, tasked to peer
            review the Monsanto manuscript, he would send it to Monsanto employees, asking for input (McHenry 2018).
            The external influence of Monsanto, on the scientific process is seen to effect not just the writing of the
            paper itself, but also the validation in peer review of the paper. External market influence, can deeply
            corrupt the validity of science.
        </p>
        <p>
            With respect to the data-oriented approach, the market we should focus on the most is big tech.
            Technological developments have always aided conceptual development. Whether it be the light microscopy,
            opening the world of the microscopic, or CRISPR opening a new world in genomics. The tech industry, seems
            to in particular have a reciprocal relationship with science.
        </p>
        <img src="resources/neuralink.jpg" alt="neuralink">
        <p> https://www.wunc.org/2024-01-30/what-to-know-about-elon-musks-neuralink-which-put-an-implant-into-a-human-brain </p>
        <img src="resources/crispr.webp" alt="crispr">
        <p>https://singularityhub.com/uploads/2021/06/crispr-cas9-genome-editing-dna-banner.jpeg?auto=webp&auto=webp&optimize=high&quality=70&width=1440 </p>
        <h1> Silicon Valley: Culture of Innovation, and Cult of Genius</h1>
        <p>
            Neuroscience is represented in the tech industry. With companies such as Neura-link, both a product of, but
            corporate influence on neuroscience research. The influence of big-tech deserves attention, as big tech has
            a very unique culture and logic. That of "innovation",  that every start up, every CEO must be a genius, a
            revolutionary. With big emphasis on "disrupting" the market. They promise innovation, revolution, and
            progress (Daub 2020). If we are to contrast this with the pharmaceutical market, we'll see that the
            pharmaceutical market is much more conservative. Naturally, people are alot more cautious about what
            medicine they take, and there is a dense body of legislation and regulation around drug development.
        </p>
        <p>
            The culture of innovation compounds in effect with the culture of genius in big-tech. A sort of
            exceptionalism about the CEO/founder and company. This is oriented both externally in marketing
            (Elizabeth Theranos, and Mark Zuckerberg, Steve Jobs) are all central figures in marketing, often the
            technology they promise can even fall behind them in marketing importance (Daub 2020). But also this
            exceptionalism is also internally oriented, in company culture and almost ritualistic practices are found
            within; from separatist compounds for corporate retreats
            (<a href="https://newrepublic.com/article/180487/balaji-srinivasan-network-state-plutocrat "> Balaji's "Tech Zionism" </a>),
            to apocalypse preparation (<a href="https://www.theguardian.com/news/2022/sep/04/super-rich-prepper-bunkers-apocalypse-survival-richest-rushkoff">Peter Thiel, Sam Altman's Apocalypse Bunkers</a>), to immortality projects
            (<a href="https://www.washingtonpost.com/style/of-interest/2023/11/06/longevity-aging-disease/">Bryon Johnson</a>)
            and cryonics (<a href="https://www.technologyreview.com/2021/09/04/1034364/altos-labs-silicon-valleys-jeff-bezos-milner-bet-living-forever/">Bezos' Altos Lab</a>)
            (Reinis 2025).
        </p>
        <img src="resources/bezos-altos-lab.png" alt="Jeff Bezos - Altos Lab">
        <p> See Jeff Bezos' (and others) <a href="https://www.technologyreview.com/2021/09/04/1034364/altos-labs-silicon-valleys-jeff-bezos-milner-bet-living-forever/">cryonic preservation of life tech start up</a>.</p>
        <img src="resources/tech-network-states.png" alt="Balaji's tech states">
        <p> Balaji Srinivasan (crypto billionaire and venture capitalist)imagines a series of "<a href=" https://theweek.com/tech/network-states-the-tech-broligarchy-who-want-to-create-new-countries">
            network states</a>" that exist concurrently, with physical states. Not
            confined to a geographic location, rather digital. A state composed of "like-minded individiuals", which he self describes
            as sort of "<a href="https://newrepublic.com/article/180487/balaji-srinivasan-network-state-plutocrat">tech zionism</a>".
        </p>
        <p>
            Both the innovative velocity that the market incentivizes (every start-up must be game-changing), but also
            the cult of genius that is engendered into silicon valley culture, should be contrasted with the culture,
            logic, and goals of scientific research. Science is slow and incremental, it is a very conservative
            philosophy of knowledge, "wait until you can prove it, once, twice, three times..., then your neighbour
            must prove it once, twice, three times...(repetition and peer review)". Science is also a collective effort,
            in its ideal it is a self-correcting and ego-less process. This is in direct contrast with the cult of
            genius, and self-exceptionalism that is in the DNA of big-tech. If the scientific field is subject to the
            market's external influences, then it is influenced by two antagonistic logics. A conservative scientific
            method and the silicon valley logic of innovation and genius. This too raises questions of epistemic
            validity, if the field of science is under influence from the tech-industry (funding and culture), our
            trust in the knowledge it produces should reflect that.
        </p>
        <p>
            Science is influenced by two competing logics. The internal influence, a philosophical goal of truth and
            betterment of man-kind. The external influence is an economic, capital influence; towards the economic
            success. However, not all fields of science are equally influenced by these forces. For instance, the
            pharmaceutical R/D field (generating much more revenue) might be more influenced by the market than
            fundamental plant biology research (comparatively, profitless). Artificial intelligence is mostly privately
            funded, with an increasing trend towards commercial models . This trend only seems to be increasing, with a
            26% growth (to 252.3 billion dollars) in private investments (Stanford HAI 2025). The data-oriented approach,
            machine learning, and AI in research represents an interface where these two influences to meet.
        </p>
        <img src="resources/increasing-private-funding-AI.png" alt="ai funding graph">
        <p>
            Stanford HAI, 2025 p. 248
        </p>
    </section>

    <section >
        <p>
            Big-tech can be seen as a force driving the "datafication" of life. More and more data is being collected.
            Social media tracking history of what you look at and like. Consumer profiles are being built by online shops.
            Everything being posted online, all data. Datafication is also occurring in research. Massive amounts of
            data can be collected, whether it be from commercial sources, or research sources. Morphological data by
            diffusion tensor imaging (Feldman et Al, 2010), or image data by more advance fine-resolution fMRI
            (Kriegeskorte and Bandettini 2007), both enabling determinations of microstructure. Some claim this is a
            bottle-neck in research; we have no shortage of data, but rather a shortage of knowledge produced from
            this data (Fregnac 2017). The "industrialization of neuroscience" as Fregnac claims, is a shift towards a
            data oriented approach enabled by technological progress, not conceptual progress.
        </p>
        <p>
            The use of AI in research, is an example of the data oriented approach in research, which involves the
            leveraging of large complex data sets, and algorithms and machine learning to turn this these large data
            sets into meaningful patterns. Large complex data sets, are typically multi-variable and heterogeneous.
            Meaning that multiple types of data, in different forms i.e. semantic and numerical, are stored in one data
            set. But large-datasets themselves are not knowledge, are not meaningful, not actionable, or even utilitarian
            (for the instrumentalists about science), until a meaning-making process occurs. For Yves Fregnac, this is
            the core issue, the trend towards datafication in science will underrepresent fundamental conceptual
            research which is what makes meaning out of data.
        </p>
        <p>
            But those who advocate for the data-oriented approach claim to have a solution. Algorithms that can extract
            meaning from this data, the principal tool is machine learning. In a sense it is a brute force approach.
            With large amounts of computational power, enabled by technological developments in computer science and
            machine learning, being leveraged to make meaning out of data. In the data-oriented approach, knowledge
            generation can be seen as the process of acquiring and making meaning out of the data. This is a departure
            from the traditional theory driven approach to science.
        </p>
        <p>
            One of the primary benefits of working with large-complex data sets is their ability to bridge the gap
            between scientific communities. Because of the heterogeneity of the data set, and the brute computation
            power of the model, we might catch patterns and trends that would be missed by a research working within a
            specific field.
        </p>
        <p>
            Despite its potential benefits, the epistemic validity of science must be questioned as the methods of
            science changes. It is dangerous to assume that the results of a data-oriented science, would be rigorous
            and legitimate in the very same way as theory-driven science is. Especially without statistical
            verification of its results.
        </p>
        <p>
            The first source of concern is the quality of data. Naturally, quality knowledge requires quality data.
            And the selection process of data, including source, population sample, method of sampling, data scraping
            are all targets of concern. This is not unique to data-driven research and sampling biases certainly exist
            in concept driven research as well.
        </p>
        <p>
            What is unique to data-driven research is the intermediate step of data pre-processing and decorating.
            Machine learning models, only take data of a specific form. In a sense, they speak a language which your
            data must be translated to. This involves whole host of issues, including questions of the validity of
            categorization, tokenization, and processing. What if we mistranslate? Considering that this process is
            automated, verification of the automated tool is needed.
        </p>
        <p>
            Additionally, the processes used to make meaning out of the data (machine learning algorithm) is also a
            point of concern because these processes are opaque. The <a href="https://www.ibm.com/think/topics/black-box-ai">
            black box of AI refers to our inability to
            understand how it works, and generates knowledge</a>. Even
            knowing every line of code, there is a sort of emergence of behavior that is seen during tuning. Where the
            parameters changed and set during training, manage to encode an internal representation of the data, and
            patterns in the data as emergent properties. How does ChatGPTs
            <a href="https://explodingtopics.com/blog/gpt-parameters"> 180 trillion parameters</a> enable its ability
            to produce realistic text. Even with full-path coverage
            (every line of code), and some way to describe the validity of the path, we still see emergence as
            preventing us from describing the validity of the model.
        </p>
        <p>
            Making this more complex is the interaction effect between the model itself, and the algorithm for
            processing/decorating data. What effect does the validity of one have on the other? Of course, every single
            question we can ask applies not just to the actual research application of a given machine learning model,
            but the training of that model. Was it trained on quality data? With valid selection and processing/decorating?.
        </p>
        <p>
            The model itself is trained on a set of training data. It might even be valid on this training data; but
            the question of cross-fitting arises, what happens when we apply it to a different data set? Does it retain
            its validity? In addition, the so-called <a href="https://www.datacamp.com/blog/curse-of-dimensionality-machine-learning">"problem of dimensionality"</a>
            arises as well; a pattern or trend can be completely formed or abolished by simply adding or removing a
            "dimension" or variable on the data set. Is the model valid cross-dimensionally?
        </p>
        <p>
            Human error is also an issue. It is common practice to "fine tune" a pre-trained model. This can human
            modulation of the hyper-parameters, a sort of top-down regulation of the model as a whole. Often, this can
            be a trial and error process. Tweaking small things, to change the outcome blindly, not knowing how the
            change was made. Confirmation bias can be an issue as well. It is possible to over-tune a model, to be
            highly sensitive to a pattern that is either illusory, or in reality, much less prevalent than the
            researcher would assume. And similarly, blind-spots can be reinforced by researcher under tuning the model
            to the blind-spot.
        </p>
        <p>
            How do we statistically test the AI model? Can we get a simple confidence interval? Or P-value? Even if we
            could for our experimental design, for it to be a truly comprehensive measure of the model validity, we
            would also have to measure its training validity, its data pre-processing/decorating validity, it's
            cross-dimensional validity. As well as any interaction effects that effects validity. To put simply, not
            clear way to measure validity exists in statistics so far.
        </p>
    </section>

    <section>
        <p>
            What is clear is the caution needed in the embracing of the data oriented approach. For all the benefits
            that data-oriented research may have, it simply does not have the epistemic certainty that theory driven
            science does.
        </p>
        <p>
            As a knowledge-generating system, the epistemic validity of science is dependent on its methods. Traditional
            theory-driven science is not perfect. Yet, we have the benefit of centuries of doing it. With statistical
            measures being developed. Regulatory bodies in place. Practices of peer-review, declaration of sources of
            funding, and control all in place. There is an existing institution of theory-driven science, that has a
            protective effect on scientific findings validity. Data-driven approach has no such certainty around it.
            Adoption of it, needs to come with adoption of new practices to ensure the sanctity of the knowledge it
            can generate. Practices which currently do no exist.
        </p>
        <p>
            Return the case of Monsanto's glyphosate (McHenry 2018), even though the circumstances of Monsanto's research where
            entirely different from the scientific ideal (in that it was under heavy external market influence), yet it
            was able to co-opt the authority and legitimacy of science, enabling glyphosate to be legally used. The
            data-oriented approach has to be seen as a fundamentally different kind of science, and should not be able
            to "borrow" the legitimacy of concept-driven science, until it can prove itself. A separation between the
            two is needed both at the individual level in how we discuss this research, but also in legislation to
            protect theory-driven science from a potentially epistemically corrupting force.
        </p>
    </section>

    <section >
        <p>
            Daub, A. (2020). What tech calls thinking : an inquiry into the intellectual bedrock of Silicon Valley.
            New York: Farrar, Straus And Giroux.
        </p>
        <p>
            Kriegeskorte N, Bandettini P. Analyzing for information, not activation, to exploit high-resolution fMRI.
            Neuroimage. 2007 Dec;38(4):649-62. doi: 10.1016/j.neuroimage.2007.02.022. Epub 2007 Feb 27. PMID: 17804260; PMCID: PMC2099257.
        </p>
        <p>
            Feldman HM, Yeatman JD, Lee ES, Barde LH, Gaman-Bean S. Diffusion tensor imaging: a review for pediatric
            researchers and clinicians. J Dev Behav Pediatr. 2010 May;31(4):346-56. doi: 10.1097/DBP.0b013e3181dcaa8b. PMID: 20453582; PMCID: PMC4245082.
        </p>
        <p>
            Fregnac, Y. Big data and the industrialization of neuroscience: A safe roadmap for understanding the brain?.
            Science 358: 470-477(2017). https://doi.org/10.1126/science.aan8866
        </p>
        <p>
            McHenry, L. B. (2018). The Monsanto Papers: Poisoning the scientific well. International Journal of Risk &
            Safety in Medicine, 29(3/4), 193â€“205. https://doi-org.ezproxy.lib.ucalgary.ca/10.3233/JRS-180028
        </p>
        <p>
            Meirmans S. How Competition for Funding Impacts Scientific Practice: Building Pre-fab Houses but no
            Cathedrals. Sci Eng Ethics. 2024 Feb 13;30(1):6. doi: 10.1007/s11948-024-00465-5. PMID: 38349578; PMCID: PMC10864468.
        </p>
        <p>
            Stanford HAI (2025) 2025 AI Index Report, accessed 2025-12-02. https://hai.stanford.edu/ai-index/2025-ai-index-report
        </p>
        <p>
            Reinis, S. THE ZEALOUS PRACTICES OF TECH INDUSTRY LEADERS. SPIR 2025. https://doi.org/10.5210/spir.v2024i0.14042
        </p>
    </section>

</body>