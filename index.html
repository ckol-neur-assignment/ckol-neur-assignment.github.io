<!DOCTYPE html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title> Home </title>
    <link rel="stylesheet" href="styles/home.css">
</head>

<body class="indent">
    <section class="blur title-div">
        <h1> The Data Oriented Approach</h1>
        <div class="img-wrapper img-wrapper2">
            <img src="resources/touch-of-god.jpg" alt="placeholder">
        </div>
        <p> By Christopher Kollar </p>
    </section>
    <section>
        <div class="blur vbox body-div">
            <h1>Science is a Knowledge Generating System</h1>
            <div class="hbox">
                <div class="item vbox text-wrapper text-wrapper1">
                    <p>
                        There is a shifting trend in scientific research, traditionally driven by conceptual development, it is
                        recently being more influenced by technological development. Technological progress, particularly in the
                        form of machine learning models is opening a new approach to research, the data-driven approach. As the
                        approach to science changes, so does the trust we can place in it changes.
                    </p>
                    <p>
                        Science is an epistemic system, a knowledge generating system. Through the scientific method, it seeks to
                        generate collectively empirically verified knowledge based on a positivistic principal of knowledge: that
                        knowledge is valid only if it can be empirically verified. This is in contrast with the knowledge-generating
                        systems of religion, which tries to generate knowledge of non-physically verifiable phenomena. The trust we
                        place in the knowledge produced by these institutions differ, because their methods of producing knowledge
                        differ.
                    </p>
                </div>
                <div class="item img-wrapper img-wrapper1">
                    <img src="resources/scientific-method.webp" alt="scientific method">
                    <p>
                        https://s-ink.org/the-scientific-method
                    </p>
                </div>
            </div>
            <div class="hbox">
                <div class="item img-wrapper img-wrapper1">
                    <img src="resources/rat.jpeg" alt="placebo rat">
                </div>
                <div class="item vbox text-wrapper text-wrapper1">
                    <p>
                        It has been argued, that the purpose of science is not to generate knowledge, but rather improve society.
                        This is could be described as an instrumentalist approach to science, where the validity of knowledge is
                        less a concern than the utility of knowledge. However, this is not reflected in real scientific practices.
                        In drug research for instance, during randomized control trials a placebo condition is common-practice. We
                        care that the drug works, not just by placebo, but by pharmacological activity. It is demonstrated, that
                        science cannot be explained as having a purely instrumentalist goal of utility, but it has an epistemic
                        goal of actual knowledge as well.
                    </p>
                </div>
            </div>
            <div class="item vbox">
                <p>
                    The epistemic validity, or "truthfulness/certainty" of the knowledge is determined by the set of procedures
                    we have developed around the scientific method. This includes peer review; a collective democratization of
                    knowledge generation. As well as statistical testing; mathematical verification of probability (note: other
                    forms of verification exist). This is built around the theory driven approach to knowledge generation:
                    hypothesis to experiment to observation. New concepts and theories are generated, and increase in likelihood
                    of truth as a body of evidence is gathered.
                    But as a knowledge generating system, if the processes and approaches used to generate the knowledge change,
                    so does the epistemic validity (our trust in knowledge) also change. Additionally, the procedures needed to
                    protect the validity of the knowledge, such as statistical-testing, need to change as well. We will look at
                    these changes in science, and how they effect the validity of the knowledge produced.
                </p>
            </div>
        </div>
    </section>
    <section>
        <div class="blur vboc body-div">
            <div class="item vbox">
                <h1> Big Tech: Competing Influence in Science </h1>
                <p>
                    the field of research is not autonomous, meaning it is subject to external forces and influence. Whether by
                    process of lobbying, or conditional funding to pools of funding. There are economic realities science has to
                    face, <a href="https://www.deloitte.com/ch/en/Industries/life-sciences-health-care/research/measuring-return-from-pharmaceutical-innovation.html">
                    it is very expensive</a>. We see this with the increase in expenditure on R/D from private companies
                    <a href="https://www.cbo.gov/publication/57126"> 10x in 2010, from what it was in the 1980s</a>,
                    that the market influence can favour certain forms of research over
                    others, applied research in particular has more immediate financial benefit for the funding companies
                    than fundamental research. These economic realities, and the need for funding creates an external influence
                    on research. (Meirmans 2024).
                </p>
                <div class="item img-wrapper img-wrapper2">
                    <img id="market-field" src="resources/market-science-field-diagram.png" alt="diagram">
                    <p>
                        Diagram showing position of the field of research, within and subject to the influences of the
                        field of the market.
                    </p>
                </div>
            </div>
        </div>
        <br>
        <div class="blur vbox body-div">
            <p>
                An example of external market influence, acting as a corrupting force can be famously seen in the case of
                Monsanto's Glyphosate herbicide, called RoundUp. Famously, Monsanto hired a panel of independent private
                researchers to publish a ghost written paper on the safety of glyphosate, using the independent researchers
                legitimacy to get published in leading toxicology journals (<a href="https://pubmed.ncbi.nlm.nih.gov/29843257/">McHenry 2018</a>). The practice of "ghost writing",
                enabled a privately written paper to gain the scientific legitimacy of the private researchers who would
                sign their name to it. While RoundUp was registered in 1974, it would take until 2015 before the IARC
                Working Group (group that critically reviews papers) to identify glyphosate as a group 2A carcinogenic agent,
                meaning it is possibly carcinogenic to humans (McHenry 2018). Additionally, the Monsanto Panel of private
                researchers would engage with interference of the peer view process, when Charles Healy, tasked to peer
                review the Monsanto manuscript, he would send it to Monsanto employees, asking for input (McHenry 2018).
                The external influence of Monsanto, on the scientific process is seen to effect not just the writing of the
                paper itself, but also the validation in peer review of the paper. External market influence, can deeply
                corrupt the validity of science.
            </p>
            <p>
                With respect to the data-oriented approach, the market we should focus on the most is big tech.
                Technological developments have always aided conceptual development. Whether it be the light microscopy,
                opening the world of the microscopic, or CRISPR opening a new world in genomics. The tech industry, seems
                to in particular have a reciprocal relationship with science.
            </p>
            <div class="item hbox">
                <div class="vbox img-wrapper">
                    <img src="resources/neuralink.jpg" alt="neuralink">
                    <p>
                        Elon Musk's
                        <a href="https://www.wunc.org/2024-01-30/what-to-know-about-elon-musks-neuralink-which-put-an-implant-into-a-human-brain">
                            Neura-link
                        </a>
                    </p>
                </div>
                <div class="vbox img-wrapper">
                    <img src="resources/crispr.webp" alt="crispr">
                    <p>
                        <a href="https://singularityhub.com/uploads/2021/06/crispr-cas9-genome-editing-dna-banner.jpeg?auto=webp&auto=webp&optimize=high&quality=70&width=1440">
                            CRISPR-Cas9
                        </a>
                        genome editing technology
                    </p>
                </div>
            </div>
        </div>
        <br>
        <div class="blur vbox body-div">
            <h1> Silicon Valley: Culture of Innovation, and Cult of Genius</h1>
            <p>
                Neuroscience is represented in the tech industry. With companies such as Neura-link, both a product of, but
                corporate influence on neuroscience research. The influence of big-tech deserves attention, as big tech has
                a very unique culture and logic. That of "innovation",  that every start up, every CEO must be a genius, a
                revolutionary. With big emphasis on "disrupting" the market. They promise innovation, revolution, and
                progress (Daub 2020). If we are to contrast this with the pharmaceutical market, we'll see that the
                pharmaceutical market is much more conservative. Naturally, people are alot more cautious about what
                medicine they take, and there is a dense body of legislation and regulation around drug development.
            </p>
            <p>
                The culture of innovation compounds in effect with the culture of genius in big-tech. A sort of
                exceptionalism about the CEO/founder and company. This is oriented both externally in marketing
                (Elizabeth Theranos, and Mark Zuckerberg, Steve Jobs) are all central figures in marketing, often the
                technology they promise can even fall behind them in marketing importance (Daub 2020). But also this
                exceptionalism is also internally oriented, in company culture and almost ritualistic practices are found
                within; from separatist compounds for corporate retreats
                (<a href="https://newrepublic.com/article/180487/balaji-srinivasan-network-state-plutocrat "> Balaji's "Tech Zionism" </a>),
                to apocalypse preparation (<a href="https://www.theguardian.com/news/2022/sep/04/super-rich-prepper-bunkers-apocalypse-survival-richest-rushkoff">Peter Thiel, Sam Altman's Apocalypse Bunkers</a>), to immortality projects
                (<a href="https://www.washingtonpost.com/style/of-interest/2023/11/06/longevity-aging-disease/">Bryon Johnson</a>)
                and cryonics (<a href="https://www.technologyreview.com/2021/09/04/1034364/altos-labs-silicon-valleys-jeff-bezos-milner-bet-living-forever/">Bezos' Altos Lab</a>)
                (Reinis 2025).
            </p>
            <div class="item hbox-wrap">
                <div class="item img-wrapper img-wrapper1">
                    <img src="resources/bezos-altos-lab.png" alt="Jeff Bezos - Altos Lab">
                    <p> See Jeff Bezos' (and others) <a href="https://www.technologyreview.com/2021/09/04/1034364/altos-labs-silicon-valleys-jeff-bezos-milner-bet-living-forever/">cryonic preservation of life tech start up</a>.</p>
                </div>
                <div class="item img-wrapper img-wrapper1">
                    <img src="resources/tech-network-states.png" alt="Balaji's tech states">
                    <p> Balaji Srinivasan (crypto billionaire and venture capitalist) imagines a series of "<a href="https://theweek.com/tech/network-states-the-tech-broligarchy-who-want-to-create-new-countries">network states</a>" that exist concurrently, with physical states. Not
                        confined to a geographic location, rather digital. A state composed of "like-minded individiuals", which he self describes
                        as sort of "<a href="https://newrepublic.com/article/180487/balaji-srinivasan-network-state-plutocrat">tech zionism</a>".
                    </p>
                </div>
            </div>
            <div class="item vbox">
                <p>
                    Both the innovative velocity that the market incentivizes (every start-up must be game-changing), but also
                    the cult of genius that is engendered into silicon valley culture, should be contrasted with the culture,
                    logic, and goals of scientific research. Science is slow and incremental, it is a very conservative
                    philosophy of knowledge, "wait until you can prove it, once, twice, three times..., then your neighbour
                    must prove it once, twice, three times...(repetition and peer review)". Science is also a collective effort,
                    in its ideal it is a self-correcting and ego-less process. This is in direct contrast with the cult of
                    genius, and self-exceptionalism that is in the DNA of big-tech. If the scientific field is subject to the
                    market's external influences, then it is influenced by two antagonistic logics. A conservative scientific
                    method and the silicon valley logic of innovation and genius. This too raises questions of epistemic
                    validity, if the field of science is under influence from the tech-industry (funding and culture), our
                    trust in the knowledge it produces should reflect that.
                </p>
                <p>
                    Science is influenced by two competing logics. The internal influence, a philosophical goal of truth and
                    betterment of man-kind. The external influence is an economic, capital influence; towards the economic
                    success. However, not all fields of science are equally influenced by these forces. For instance, the
                    pharmaceutical R/D field (generating much more revenue) might be more influenced by the market than
                    fundamental plant biology research (comparatively, profitless). Artificial intelligence is mostly privately
                    funded, with an increasing trend towards commercial models . This trend only seems to be increasing, with a
                    26% growth (to 252.3 billion dollars) in private investments (Stanford HAI 2025). The data-oriented approach,
                    machine learning, and AI in research represents an interface where these two influences to meet.
                </p>
                <div class="item img-wrapper img-wrapper2">
                    <img src="resources/increasing-private-funding-AI.png" alt="ai funding graph">
                    <p>
                        Stanford HAI, 2025 p. 248
                    </p>
                    <p>
                        Observe the massive amounts of money from private investment sources funneling into AI development.
                        Ask yourself how this private source can influence the technology itself.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <section>
        <div class="blur vbox body-div">
            <div class="vbox">
                <h1>
                    Can we trust the knowledge produced from the data-oriented artificial intelligence approach?
                </h1>

                <p>
                    Big-tech can be seen as a force driving the "datafication" of life. More and more data is being collected.
                    Social media tracking history of what you look at and like. Consumer profiles are being built by online shops.
                    Everything being posted online, all data. Datafication is also occurring in research. Massive amounts of
                    data can be collected, whether it be from commercial sources, or research sources. Morphological data by
                    diffusion tensor imaging (<a href="https://pubmed.ncbi.nlm.nih.gov/20453582/">Feldman et Al, 2010</a>), or image data by more advance fine-resolution fMRI
                    (<a href="https://pubmed.ncbi.nlm.nih.gov/17804260/">Kriegeskorte and Bandettini 2007</a>),
                    both enabling determinations of microstructure. Some claim this is a
                    bottle-neck in research; we have no shortage of data, but rather a shortage of knowledge produced from
                    this data (Fregnac 2017). The "industrialization of neuroscience" as Fregnac claims, is a shift towards a
                    data oriented approach enabled by technological progress, not conceptual progress.
                </p>
            </div>
            <div class="img-wrapper img-wrapper2">
                <img src="resources/industrialization-of-neuroscience.png" alt="Yves Fregnac">
                <p>(<a href="https://www.science.org/doi/10.1126/science.aan8866">Fregnac 2017</a>)</p>
            </div>
            <br>
            <div class="hbox">
               <div class="text-wrapper text-wrapper1">
                   <p>
                       The use of AI in research, is an example of the data oriented approach in research, which involves the
                       leveraging of large complex data sets, and algorithms and machine learning to turn this these large data
                       sets into meaningful patterns. Large complex data sets, are typically multi-variable and heterogeneous.
                       Meaning that multiple types of data, are stored in one data
                       set. But large-datasets themselves are not knowledge, are not meaningful, not actionable, or even utilitarian
                       (for the instrumentalists about science), until a meaning-making process occurs. For Yves Fregnac, this is
                       the core issue, the trend towards datafication in science will underrepresent fundamental conceptual
                       research which is what makes meaning out of data (Fregnac 2017).
                   </p>
               </div> 
                <div class="img-wrapper img-wrapper1">
                    <img src="resources/high-dimensional-data-set-precdentral-gyrus.png" alt="large-complex-dataset">
                    <p><a href="https://naturalistic-data.org/content/hypertools.html">visualization of large complex data set</a></p>
                </div>
            </div>
            <div class="vbox">
                <p>
                    But those who advocate for the data-oriented approach claim to have a solution. Algorithms that can extract
                    meaning from this data, the principal tool is machine learning. In a sense it is a brute force approach.
                    With large amounts of computational power, enabled by technological developments in computer science and
                    machine learning, being leveraged to make meaning out of data. In the data-oriented approach, knowledge
                    generation can be seen as the process of acquiring and making meaning out of the data. This is a departure
                    from the traditional theory driven approach to science.
                    One of the primary benefits of working with large-complex data sets is their ability to bridge the gap
                    between scientific communities. Because of the heterogeneity of the data set, and the brute computation
                    power of the model, we might catch patterns and trends that would be missed by a research working within a
                    specific field.
                    Despite its potential benefits, the epistemic validity of science must be questioned as the methods of
                    science changes. It is dangerous to assume that the results of a data-oriented science, would be rigorous
                    and legitimate in the very same way as theory-driven science is. Especially without statistical
                    verification of its results.
                </p>
                <p>
                    The first source of concern is the quality of data. Naturally, quality knowledge requires quality data.
                    And the selection process of data, including source, population sample, method of sampling, data scraping
                    are all targets of concern. This is not unique to data-driven research and sampling biases certainly exist
                    in concept driven research as well.
                </p>
                <div class="img-wrapper img-wrapper4">
                    <img src="resources/v's-of-data.jpg" alt="v's of data">
                    <p><a href="https://www.duckcreek.com/blog/the-6-vs-of-big-data-in-the-insurance-industry/">img source</a></p>
                </div>
                <p>
                    What is unique to data-driven research is the intermediate step of data pre-processing and decorating.
                    Machine learning models, only take data of a specific form. In a sense, they speak a language which your
                    data must be translated to. This involves whole host of issues, including questions of the validity of
                    categorization, tokenization, and processing. What if we mistranslate? Considering that this process is
                    automated, verification of the automated tool is needed. Additionally, there is little to no regulation, or guidelines
                    for proper practice of data management, what metadata is needed, what organizational practices must be used?
                    How can we tell whether the data is ready for AI use?
                </p>
                <div class="quote">
                    <p>
                        <em>
                            "Sixty-three percent of organizations either do not have or are unsure if they have the right data management practices for AI, according to a survey by
                            <a href="https://www.gartner.com/en/newsroom/press-releases/2025-02-26-lack-of-ai-ready-data-puts-ai-projects-at-risk">Gartner</a>"
                        </em>
                    </p>
                    <p>
                        "<em>
                        uses of data are not well-documented, and data is often collected in siloes across various repositories, multiple systems and platforms. Organizations lack the required practice and metadata to assess the
                        <a href="https://www.gartner.com/en/newsroom/press-releases/2025-02-26-lack-of-ai-ready-data-puts-ai-projects-at-risk">readiness of data for AI</a>.
                    </em>"
                    </p>
                </div>
            </div>
            <br>
            <div class="vbox">
                <div class="hbox">
                    <div class="img-wrapper img-wrapper3">
                        <img src="resources/black-box.webp" alt="black-box-diagram">
                        <p>
                            Emergent properties of AI make it nearly impossible to determine what is relevant to the conclusions
                            it comes to.
                        </p>
                        <p>
                            <a href="https://miro.medium.com/v2/resize:fit:750/format:webp/1*FgZ2ivFL6rts5DKOsmPDRA.png"> img source </a>
                        </p>
                    </div>
                    <div class="vbox text-wrapper text-wrapper2">
                        <p>
                            Additionally, the processes used to make meaning out of the data (machine learning algorithm) is also a
                            point of concern because these processes are opaque. The <a href="https://www.ibm.com/think/topics/black-box-ai">
                            black box of AI refers to our inability to
                            understand how it works, and generates knowledge</a>. Even
                            knowing every line of code, there is a sort of emergence of behavior that is seen during tuning. Where the
                            parameters changed and set during training, manage to encode an internal representation of the data, and
                            patterns in the data as emergent properties. How does ChatGPTs
                            <a href="https://explodingtopics.com/blog/gpt-parameters"> 180 trillion parameters</a> enable its ability
                            to produce realistic text. Even with full-path coverage
                            (every line of code), and some way to describe the validity of the path, we still see emergence as
                            preventing us from describing the validity of the model.
                        </p>
                        <p>
                            Making this more complex is the interaction effect between the model itself, and the algorithm for
                            processing/decorating data. What effect does the validity of one have on the other? Of course, every single
                            question we can ask applies not just to the actual research application of a given machine learning model,
                            but the training of that model. Was it trained on quality data? With valid selection and processing/decorating?.
                        </p>
                    </div>
                </div>
                <br>
                <p>
                    The model itself is trained on a set of training data. It might even be valid on this training data; but
                    the question of cross-fitting arises, what happens when we apply it to a different data set? Does it retain
                    its validity? In addition, the so-called <a href="https://www.datacamp.com/blog/curse-of-dimensionality-machine-learning">"problem of dimensionality"</a>
                    arises as well; a pattern or trend can be completely formed or abolished by simply adding or removing a
                    "dimension" or variable on the data set. Is the model valid cross-dimensionally?
                </p>
                <p>
                    Human error is also an issue. It is common practice to "fine tune" a pre-trained model. This can be human
                    modulation of the <a href="https://www.ibm.com/think/topics/hyperparameter-tuning">hyper-parameters</a>,
                    a sort of top-down regulation of the model as a whole. Often, this can
                    be a trial and error process. Tweaking small things, to change the outcome blindly, not knowing how the
                    change was made. Confirmation bias can be an issue as well. It is possible to over-tune a model, to be
                    highly sensitive to a pattern that is either illusory, or in reality, much less prevalent than the
                    researcher would assume. And similarly, blind-spots can be reinforced by researcher under tuning the model
                    to the blind-spot.
                </p>
                <p>
                    How do we statistically test the AI model? Can we get a simple confidence interval? Or P-value? Even if we
                    could for our experimental design, for it to be a truly comprehensive measure of the model validity, we
                    would also have to measure its training validity, its data pre-processing/decorating validity, it's
                    cross-dimensional validity. As well as any interaction effects that effects validity. To put simply, not
                    clear way to measure validity exists in statistics so far.
                </p>
            </div>
        </div>
    </section>

    <section>
        <div class="blur vbox body-div">
            <h1>
                The Data-Oriented Approach: Conclusion
            </h1>
            <div class="quote">
                <p>
                    '<em>
                    This approach, which Sabina Leonelli characterised as data-centric, involves “focusing more on the processes through which research is carried out than on its ultimate outcomes”
                    '</em>
                </p>
                <p>
                    <a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=science-big-data">(Leonelli 2020)</a>
                </p>
            </div>
            <p>
                What is clear is the caution needed in the embracing of the data oriented approach. For all the benefits
                that data-oriented research may have, it simply does not have the epistemic certainty that theory driven
                science does.
                As a knowledge-generating system, the epistemic validity of science is dependent on its methods. Traditional
                theory-driven science is not perfect. Yet, we have the benefit of centuries of doing it. With statistical
                measures being developed. Regulatory bodies in place. Practices of peer-review, declaration of sources of
                funding, and control all in place. There is an existing institution of theory-driven science, that has a
                protective effect on scientific findings validity. Data-driven approach has no such certainty around it.
                Adoption of it, needs to come with adoption of new practices to ensure the sanctity of the knowledge it
                can generate. Practices which currently do no exist.
            </p>
            <p>
                Return the case of Monsanto's glyphosate (<a href="https://pubmed.ncbi.nlm.nih.gov/29843257/">McHenry 2018</a>), even though the circumstances of Monsanto's research where
                entirely different from the scientific ideal (in that it was under heavy external market influence), yet it
                was able to co-opt the authority and legitimacy of science, enabling glyphosate to be legally used. The
                data-oriented approach has to be seen as a fundamentally different kind of science, and should not be able
                to "borrow" the legitimacy of concept-driven science, until it can prove itself. A separation between the
                two is needed both at the individual level in how we discuss this research, but also in legislation to
                protect theory-driven science from a potentially epistemically corrupting force.
            </p>
        </div>
    </section>

    <section>
        <div class="blur vbox body-div">
            <h2>
                References
            </h2>
            <p>
                Note that not all references are present in this section, websites I am mostly using for a one off examples, or just a picture
                are just cited as an embedded link. This is for citations that have influenced my opinion and thoughts on the subject.
            </p>
            <p>
                Daub, A. (2020). What tech calls thinking : an inquiry into the intellectual bedrock of Silicon Valley.
                New York: Farrar, Straus And Giroux.
            </p>
            <p>
                Kriegeskorte N, Bandettini P. Analyzing for information, not activation, to exploit high-resolution fMRI.
                Neuroimage. 2007 Dec;38(4):649-62. doi: 10.1016/j.neuroimage.2007.02.022. Epub 2007 Feb 27. PMID: 17804260; PMCID: PMC2099257.
            </p>
            <p>
                Leonelli, Sabina, "Scientific Research and Big Data", The Stanford Encyclopedia of Philosophy (Summer 2020 Edition), Edward N. Zalta (ed.). https://plato.stanford.edu/archives/sum2020/entries/science-big-data/
            </p>
            <p>
                Feldman HM, Yeatman JD, Lee ES, Barde LH, Gaman-Bean S. Diffusion tensor imaging: a review for pediatric
                researchers and clinicians. J Dev Behav Pediatr. 2010 May;31(4):346-56. doi: 10.1097/DBP.0b013e3181dcaa8b. PMID: 20453582; PMCID: PMC4245082.
            </p>
            <p>
                Fregnac, Y. Big data and the industrialization of neuroscience: A safe roadmap for understanding the brain?.
                Science 358: 470-477(2017). https://doi.org/10.1126/science.aan8866
            </p>
            <p>
                McHenry, L. B. (2018). The Monsanto Papers: Poisoning the scientific well. International Journal of Risk &
                Safety in Medicine, 29(3/4), 193–205. https://doi-org.ezproxy.lib.ucalgary.ca/10.3233/JRS-180028
            </p>
            <p>
                Meirmans S. How Competition for Funding Impacts Scientific Practice: Building Pre-fab Houses but no
                Cathedrals. Sci Eng Ethics. 2024 Feb 13;30(1):6. doi: 10.1007/s11948-024-00465-5. PMID: 38349578; PMCID: PMC10864468.
            </p>
            <p>
                Stanford HAI (2025) 2025 AI Index Report, accessed 2025-12-02. https://hai.stanford.edu/ai-index/2025-ai-index-report
            </p>
            <p>
                Reinis, S. THE ZEALOUS PRACTICES OF TECH INDUSTRY LEADERS. SPIR 2025. https://doi.org/10.5210/spir.v2024i0.14042
            </p>
        </div>
    </section>

</body>